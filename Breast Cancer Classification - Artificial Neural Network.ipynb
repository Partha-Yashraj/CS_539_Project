{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Breast Cancer Classification (ANN).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5bBKANbRYda"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf \n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bc_data = sklearn.datasets.load_breast_cancer()"
      ],
      "metadata": {
        "id": "4s2WP2dkTiVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(bc_data.data, columns = bc_data.feature_names)\n",
        "df[\"target\"] = bc_data.target\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1R0ySgeTiv6",
        "outputId": "058272bd-30e7-490b-b849-ada1b4bc4425"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
            "0          17.99         10.38          122.80     1001.0          0.11840   \n",
            "1          20.57         17.77          132.90     1326.0          0.08474   \n",
            "2          19.69         21.25          130.00     1203.0          0.10960   \n",
            "3          11.42         20.38           77.58      386.1          0.14250   \n",
            "4          20.29         14.34          135.10     1297.0          0.10030   \n",
            "..           ...           ...             ...        ...              ...   \n",
            "564        21.56         22.39          142.00     1479.0          0.11100   \n",
            "565        20.13         28.25          131.20     1261.0          0.09780   \n",
            "566        16.60         28.08          108.30      858.1          0.08455   \n",
            "567        20.60         29.33          140.10     1265.0          0.11780   \n",
            "568         7.76         24.54           47.92      181.0          0.05263   \n",
            "\n",
            "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
            "0             0.27760         0.30010              0.14710         0.2419   \n",
            "1             0.07864         0.08690              0.07017         0.1812   \n",
            "2             0.15990         0.19740              0.12790         0.2069   \n",
            "3             0.28390         0.24140              0.10520         0.2597   \n",
            "4             0.13280         0.19800              0.10430         0.1809   \n",
            "..                ...             ...                  ...            ...   \n",
            "564           0.11590         0.24390              0.13890         0.1726   \n",
            "565           0.10340         0.14400              0.09791         0.1752   \n",
            "566           0.10230         0.09251              0.05302         0.1590   \n",
            "567           0.27700         0.35140              0.15200         0.2397   \n",
            "568           0.04362         0.00000              0.00000         0.1587   \n",
            "\n",
            "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
            "0                   0.07871  ...          17.33           184.60      2019.0   \n",
            "1                   0.05667  ...          23.41           158.80      1956.0   \n",
            "2                   0.05999  ...          25.53           152.50      1709.0   \n",
            "3                   0.09744  ...          26.50            98.87       567.7   \n",
            "4                   0.05883  ...          16.67           152.20      1575.0   \n",
            "..                      ...  ...            ...              ...         ...   \n",
            "564                 0.05623  ...          26.40           166.10      2027.0   \n",
            "565                 0.05533  ...          38.25           155.00      1731.0   \n",
            "566                 0.05648  ...          34.12           126.70      1124.0   \n",
            "567                 0.07016  ...          39.42           184.60      1821.0   \n",
            "568                 0.05884  ...          30.37            59.16       268.6   \n",
            "\n",
            "     worst smoothness  worst compactness  worst concavity  \\\n",
            "0             0.16220            0.66560           0.7119   \n",
            "1             0.12380            0.18660           0.2416   \n",
            "2             0.14440            0.42450           0.4504   \n",
            "3             0.20980            0.86630           0.6869   \n",
            "4             0.13740            0.20500           0.4000   \n",
            "..                ...                ...              ...   \n",
            "564           0.14100            0.21130           0.4107   \n",
            "565           0.11660            0.19220           0.3215   \n",
            "566           0.11390            0.30940           0.3403   \n",
            "567           0.16500            0.86810           0.9387   \n",
            "568           0.08996            0.06444           0.0000   \n",
            "\n",
            "     worst concave points  worst symmetry  worst fractal dimension  target  \n",
            "0                  0.2654          0.4601                  0.11890       0  \n",
            "1                  0.1860          0.2750                  0.08902       0  \n",
            "2                  0.2430          0.3613                  0.08758       0  \n",
            "3                  0.2575          0.6638                  0.17300       0  \n",
            "4                  0.1625          0.2364                  0.07678       0  \n",
            "..                    ...             ...                      ...     ...  \n",
            "564                0.2216          0.2060                  0.07115       0  \n",
            "565                0.1628          0.2572                  0.06637       0  \n",
            "566                0.1418          0.2218                  0.07820       0  \n",
            "567                0.2650          0.4087                  0.12400       0  \n",
            "568                0.0000          0.2871                  0.07039       1  \n",
            "\n",
            "[569 rows x 31 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNd1tsLwTl9E",
        "outputId": "7dd856b9-1ac7-47e3-ee2d-680b48a351b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 31 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   mean radius              569 non-null    float64\n",
            " 1   mean texture             569 non-null    float64\n",
            " 2   mean perimeter           569 non-null    float64\n",
            " 3   mean area                569 non-null    float64\n",
            " 4   mean smoothness          569 non-null    float64\n",
            " 5   mean compactness         569 non-null    float64\n",
            " 6   mean concavity           569 non-null    float64\n",
            " 7   mean concave points      569 non-null    float64\n",
            " 8   mean symmetry            569 non-null    float64\n",
            " 9   mean fractal dimension   569 non-null    float64\n",
            " 10  radius error             569 non-null    float64\n",
            " 11  texture error            569 non-null    float64\n",
            " 12  perimeter error          569 non-null    float64\n",
            " 13  area error               569 non-null    float64\n",
            " 14  smoothness error         569 non-null    float64\n",
            " 15  compactness error        569 non-null    float64\n",
            " 16  concavity error          569 non-null    float64\n",
            " 17  concave points error     569 non-null    float64\n",
            " 18  symmetry error           569 non-null    float64\n",
            " 19  fractal dimension error  569 non-null    float64\n",
            " 20  worst radius             569 non-null    float64\n",
            " 21  worst texture            569 non-null    float64\n",
            " 22  worst perimeter          569 non-null    float64\n",
            " 23  worst area               569 non-null    float64\n",
            " 24  worst smoothness         569 non-null    float64\n",
            " 25  worst compactness        569 non-null    float64\n",
            " 26  worst concavity          569 non-null    float64\n",
            " 27  worst concave points     569 non-null    float64\n",
            " 28  worst symmetry           569 non-null    float64\n",
            " 29  worst fractal dimension  569 non-null    float64\n",
            " 30  target                   569 non-null    int64  \n",
            "dtypes: float64(30), int64(1)\n",
            "memory usage: 137.9 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCPJG08TTnR3",
        "outputId": "41545320-6fd0-4ea6-da50-b9fc6ac8b220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "mean radius                0\n",
              "mean texture               0\n",
              "mean perimeter             0\n",
              "mean area                  0\n",
              "mean smoothness            0\n",
              "mean compactness           0\n",
              "mean concavity             0\n",
              "mean concave points        0\n",
              "mean symmetry              0\n",
              "mean fractal dimension     0\n",
              "radius error               0\n",
              "texture error              0\n",
              "perimeter error            0\n",
              "area error                 0\n",
              "smoothness error           0\n",
              "compactness error          0\n",
              "concavity error            0\n",
              "concave points error       0\n",
              "symmetry error             0\n",
              "fractal dimension error    0\n",
              "worst radius               0\n",
              "worst texture              0\n",
              "worst perimeter            0\n",
              "worst area                 0\n",
              "worst smoothness           0\n",
              "worst compactness          0\n",
              "worst concavity            0\n",
              "worst concave points       0\n",
              "worst symmetry             0\n",
              "worst fractal dimension    0\n",
              "target                     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:,:10]\n",
        "print(X)\n",
        "y = df.iloc[:,-1]\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asJcshTlToiS",
        "outputId": "a06c3b1c-87c4-46be-f13a-0a789f04070d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
            "0          17.99         10.38          122.80     1001.0          0.11840   \n",
            "1          20.57         17.77          132.90     1326.0          0.08474   \n",
            "2          19.69         21.25          130.00     1203.0          0.10960   \n",
            "3          11.42         20.38           77.58      386.1          0.14250   \n",
            "4          20.29         14.34          135.10     1297.0          0.10030   \n",
            "..           ...           ...             ...        ...              ...   \n",
            "564        21.56         22.39          142.00     1479.0          0.11100   \n",
            "565        20.13         28.25          131.20     1261.0          0.09780   \n",
            "566        16.60         28.08          108.30      858.1          0.08455   \n",
            "567        20.60         29.33          140.10     1265.0          0.11780   \n",
            "568         7.76         24.54           47.92      181.0          0.05263   \n",
            "\n",
            "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
            "0             0.27760         0.30010              0.14710         0.2419   \n",
            "1             0.07864         0.08690              0.07017         0.1812   \n",
            "2             0.15990         0.19740              0.12790         0.2069   \n",
            "3             0.28390         0.24140              0.10520         0.2597   \n",
            "4             0.13280         0.19800              0.10430         0.1809   \n",
            "..                ...             ...                  ...            ...   \n",
            "564           0.11590         0.24390              0.13890         0.1726   \n",
            "565           0.10340         0.14400              0.09791         0.1752   \n",
            "566           0.10230         0.09251              0.05302         0.1590   \n",
            "567           0.27700         0.35140              0.15200         0.2397   \n",
            "568           0.04362         0.00000              0.00000         0.1587   \n",
            "\n",
            "     mean fractal dimension  \n",
            "0                   0.07871  \n",
            "1                   0.05667  \n",
            "2                   0.05999  \n",
            "3                   0.09744  \n",
            "4                   0.05883  \n",
            "..                      ...  \n",
            "564                 0.05623  \n",
            "565                 0.05533  \n",
            "566                 0.05648  \n",
            "567                 0.07016  \n",
            "568                 0.05884  \n",
            "\n",
            "[569 rows x 10 columns]\n",
            "0      0\n",
            "1      0\n",
            "2      0\n",
            "3      0\n",
            "4      0\n",
            "      ..\n",
            "564    0\n",
            "565    0\n",
            "566    0\n",
            "567    0\n",
            "568    1\n",
            "Name: target, Length: 569, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=0.7,random_state=0)"
      ],
      "metadata": {
        "id": "BcjvFCb9T4vI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ss = StandardScaler()\n",
        "\n",
        "X_train_std = ss.fit_transform(X_train)\n",
        "X_test_std = ss.transform(X_test)"
      ],
      "metadata": {
        "id": "7dRjWuaJT8gj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(0)\n",
        "\n",
        "model = keras.Sequential([\n",
        "                          keras.layers.Flatten(input_shape=(10,)),\n",
        "                          keras.layers.Dense(20, activation='relu'),\n",
        "                          keras.layers.Dense(20, activation='relu'),\n",
        "                          keras.layers.Dense(2, activation='sigmoid')])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "XkJLyzhAUHj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn = model.fit(X_train_std, y_train, validation_split=0.1, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvWste75peHH",
        "outputId": "7c17ac37-db37-4889-e5e7-550f832e45c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "12/12 [==============================] - 2s 44ms/step - loss: 0.6102 - accuracy: 0.7095 - val_loss: 0.5267 - val_accuracy: 0.7250\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.5045 - accuracy: 0.7821 - val_loss: 0.4510 - val_accuracy: 0.8000\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.4174 - accuracy: 0.8547 - val_loss: 0.3865 - val_accuracy: 0.9000\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3471 - accuracy: 0.8855 - val_loss: 0.3323 - val_accuracy: 0.9250\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2890 - accuracy: 0.9190 - val_loss: 0.2855 - val_accuracy: 0.9500\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2450 - accuracy: 0.9385 - val_loss: 0.2495 - val_accuracy: 0.9750\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2126 - accuracy: 0.9441 - val_loss: 0.2234 - val_accuracy: 0.9750\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.1901 - accuracy: 0.9469 - val_loss: 0.2075 - val_accuracy: 0.9750\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.1734 - accuracy: 0.9469 - val_loss: 0.1984 - val_accuracy: 0.9500\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1612 - accuracy: 0.9497 - val_loss: 0.1907 - val_accuracy: 0.9500\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1511 - accuracy: 0.9497 - val_loss: 0.1850 - val_accuracy: 0.9500\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1441 - accuracy: 0.9497 - val_loss: 0.1786 - val_accuracy: 0.9500\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1378 - accuracy: 0.9525 - val_loss: 0.1817 - val_accuracy: 0.9250\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1318 - accuracy: 0.9525 - val_loss: 0.1786 - val_accuracy: 0.9250\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1278 - accuracy: 0.9553 - val_loss: 0.1815 - val_accuracy: 0.9250\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1239 - accuracy: 0.9581 - val_loss: 0.1792 - val_accuracy: 0.9250\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1198 - accuracy: 0.9609 - val_loss: 0.1900 - val_accuracy: 0.9250\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1173 - accuracy: 0.9637 - val_loss: 0.1921 - val_accuracy: 0.9250\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1145 - accuracy: 0.9637 - val_loss: 0.1952 - val_accuracy: 0.9250\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1118 - accuracy: 0.9637 - val_loss: 0.1934 - val_accuracy: 0.9250\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1099 - accuracy: 0.9637 - val_loss: 0.1903 - val_accuracy: 0.9250\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1078 - accuracy: 0.9637 - val_loss: 0.1933 - val_accuracy: 0.9250\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1060 - accuracy: 0.9637 - val_loss: 0.1979 - val_accuracy: 0.9250\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.1039 - accuracy: 0.9721 - val_loss: 0.2026 - val_accuracy: 0.9250\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1025 - accuracy: 0.9721 - val_loss: 0.2088 - val_accuracy: 0.9250\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1007 - accuracy: 0.9749 - val_loss: 0.2080 - val_accuracy: 0.9250\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0995 - accuracy: 0.9721 - val_loss: 0.2197 - val_accuracy: 0.9250\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0984 - accuracy: 0.9721 - val_loss: 0.2141 - val_accuracy: 0.9250\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0966 - accuracy: 0.9777 - val_loss: 0.2080 - val_accuracy: 0.9250\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0965 - accuracy: 0.9749 - val_loss: 0.2025 - val_accuracy: 0.9250\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0950 - accuracy: 0.9749 - val_loss: 0.2064 - val_accuracy: 0.9250\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0944 - accuracy: 0.9749 - val_loss: 0.1975 - val_accuracy: 0.9250\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0926 - accuracy: 0.9777 - val_loss: 0.2059 - val_accuracy: 0.9250\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0909 - accuracy: 0.9749 - val_loss: 0.2123 - val_accuracy: 0.9250\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0897 - accuracy: 0.9749 - val_loss: 0.2146 - val_accuracy: 0.9250\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0886 - accuracy: 0.9749 - val_loss: 0.2167 - val_accuracy: 0.9250\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0877 - accuracy: 0.9749 - val_loss: 0.2157 - val_accuracy: 0.9250\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0867 - accuracy: 0.9777 - val_loss: 0.2128 - val_accuracy: 0.9250\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0859 - accuracy: 0.9777 - val_loss: 0.2155 - val_accuracy: 0.9250\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0849 - accuracy: 0.9777 - val_loss: 0.2175 - val_accuracy: 0.9250\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0840 - accuracy: 0.9777 - val_loss: 0.2199 - val_accuracy: 0.9250\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0835 - accuracy: 0.9777 - val_loss: 0.2160 - val_accuracy: 0.9250\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0821 - accuracy: 0.9777 - val_loss: 0.2216 - val_accuracy: 0.9250\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0807 - accuracy: 0.9749 - val_loss: 0.2328 - val_accuracy: 0.9250\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0804 - accuracy: 0.9777 - val_loss: 0.2299 - val_accuracy: 0.9250\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0796 - accuracy: 0.9777 - val_loss: 0.2287 - val_accuracy: 0.9250\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0786 - accuracy: 0.9777 - val_loss: 0.2274 - val_accuracy: 0.9250\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0780 - accuracy: 0.9777 - val_loss: 0.2276 - val_accuracy: 0.9250\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0776 - accuracy: 0.9777 - val_loss: 0.2283 - val_accuracy: 0.9250\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0767 - accuracy: 0.9777 - val_loss: 0.2339 - val_accuracy: 0.9250\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0760 - accuracy: 0.9804 - val_loss: 0.2302 - val_accuracy: 0.9250\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0750 - accuracy: 0.9804 - val_loss: 0.2303 - val_accuracy: 0.9250\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0746 - accuracy: 0.9804 - val_loss: 0.2429 - val_accuracy: 0.9250\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0739 - accuracy: 0.9804 - val_loss: 0.2398 - val_accuracy: 0.9250\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0733 - accuracy: 0.9804 - val_loss: 0.2409 - val_accuracy: 0.9250\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0726 - accuracy: 0.9804 - val_loss: 0.2442 - val_accuracy: 0.9250\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0717 - accuracy: 0.9777 - val_loss: 0.2423 - val_accuracy: 0.9250\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0712 - accuracy: 0.9777 - val_loss: 0.2431 - val_accuracy: 0.9250\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0706 - accuracy: 0.9777 - val_loss: 0.2435 - val_accuracy: 0.9250\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0699 - accuracy: 0.9777 - val_loss: 0.2460 - val_accuracy: 0.9250\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0694 - accuracy: 0.9777 - val_loss: 0.2491 - val_accuracy: 0.9250\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0689 - accuracy: 0.9777 - val_loss: 0.2498 - val_accuracy: 0.9250\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0684 - accuracy: 0.9777 - val_loss: 0.2482 - val_accuracy: 0.9250\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0677 - accuracy: 0.9777 - val_loss: 0.2494 - val_accuracy: 0.9250\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0671 - accuracy: 0.9777 - val_loss: 0.2495 - val_accuracy: 0.9250\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0668 - accuracy: 0.9777 - val_loss: 0.2513 - val_accuracy: 0.9250\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0661 - accuracy: 0.9777 - val_loss: 0.2641 - val_accuracy: 0.9250\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0657 - accuracy: 0.9749 - val_loss: 0.2809 - val_accuracy: 0.9250\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0660 - accuracy: 0.9721 - val_loss: 0.2702 - val_accuracy: 0.9250\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0649 - accuracy: 0.9721 - val_loss: 0.2639 - val_accuracy: 0.9250\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0646 - accuracy: 0.9721 - val_loss: 0.2734 - val_accuracy: 0.9250\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0642 - accuracy: 0.9721 - val_loss: 0.2696 - val_accuracy: 0.9250\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0632 - accuracy: 0.9777 - val_loss: 0.2585 - val_accuracy: 0.9250\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0631 - accuracy: 0.9804 - val_loss: 0.2512 - val_accuracy: 0.9250\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0627 - accuracy: 0.9832 - val_loss: 0.2515 - val_accuracy: 0.9250\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0619 - accuracy: 0.9804 - val_loss: 0.2608 - val_accuracy: 0.9250\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0611 - accuracy: 0.9832 - val_loss: 0.2685 - val_accuracy: 0.9250\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0606 - accuracy: 0.9832 - val_loss: 0.2624 - val_accuracy: 0.9250\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0597 - accuracy: 0.9832 - val_loss: 0.2666 - val_accuracy: 0.9250\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0593 - accuracy: 0.9832 - val_loss: 0.2717 - val_accuracy: 0.9250\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0590 - accuracy: 0.9832 - val_loss: 0.2690 - val_accuracy: 0.9250\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0585 - accuracy: 0.9832 - val_loss: 0.2744 - val_accuracy: 0.9250\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0579 - accuracy: 0.9832 - val_loss: 0.2737 - val_accuracy: 0.9250\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0576 - accuracy: 0.9804 - val_loss: 0.2746 - val_accuracy: 0.9250\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0572 - accuracy: 0.9832 - val_loss: 0.2672 - val_accuracy: 0.9250\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0567 - accuracy: 0.9832 - val_loss: 0.2753 - val_accuracy: 0.9250\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0559 - accuracy: 0.9832 - val_loss: 0.2760 - val_accuracy: 0.9250\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0555 - accuracy: 0.9832 - val_loss: 0.2756 - val_accuracy: 0.9250\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0547 - accuracy: 0.9804 - val_loss: 0.2817 - val_accuracy: 0.9250\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0547 - accuracy: 0.9804 - val_loss: 0.2862 - val_accuracy: 0.9250\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0542 - accuracy: 0.9804 - val_loss: 0.2782 - val_accuracy: 0.9250\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0536 - accuracy: 0.9832 - val_loss: 0.2853 - val_accuracy: 0.9250\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0528 - accuracy: 0.9832 - val_loss: 0.2746 - val_accuracy: 0.9250\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0528 - accuracy: 0.9832 - val_loss: 0.2708 - val_accuracy: 0.9250\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0534 - accuracy: 0.9832 - val_loss: 0.2536 - val_accuracy: 0.9250\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0529 - accuracy: 0.9804 - val_loss: 0.2703 - val_accuracy: 0.9250\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0510 - accuracy: 0.9832 - val_loss: 0.2882 - val_accuracy: 0.9250\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0507 - accuracy: 0.9832 - val_loss: 0.3003 - val_accuracy: 0.9250\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0505 - accuracy: 0.9832 - val_loss: 0.2802 - val_accuracy: 0.9250\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0504 - accuracy: 0.9804 - val_loss: 0.3031 - val_accuracy: 0.9250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(nn.history['accuracy'])\n",
        "plt.plot(nn.history['val_accuracy'])\n",
        "\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "\n",
        "plt.legend(['Training Data', 'Validation Data'], loc = 'lower right')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "Mj7SJYCtqJyo",
        "outputId": "bf4d212c-54dc-40e4-9b0c-c4887c83f5db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f8ef6ae3490>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test_std, y_test)\n",
        "print(\"Accuracy:\",accuracy*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umka2E-bqfnO",
        "outputId": "d9ac6736-2b9f-4bfe-cf6b-31942ccb9fc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1362 - accuracy: 0.9240\n",
            "0.9239766001701355\n"
          ]
        }
      ]
    }
  ]
}